{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN\n",
    "class Fashion(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Fashion,self).__init__()\n",
    "        \n",
    "        # define the convolution layers\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 7)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.drop1 = torch.nn.Dropout2d(p=0.25)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3)\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.drop2 = torch.nn.Dropout2d(p=0.25)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3)\n",
    "        self.drop3 = torch.nn.Dropout2d(p=0.4)\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(2*2*128, 128)\n",
    "        self.drop4 = torch.nn.Dropout2d(p=0.3)\n",
    "        \n",
    "        self.fc5 = torch.nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.drop3(x)\n",
    "        \n",
    "        #Recall that the -1 infers this dimension from the other given dimension\n",
    "        x = x.view(-1, 2*2*128)\n",
    "        \n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.drop4(x)\n",
    "\n",
    "        #(activation applied later)\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instance of the Conv Net\n",
    "cnn = Fashion()\n",
    "#loss function and optimizer for updating weights\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajaysingh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  app.launch_new_instance()\n",
      "/Users/ajaysingh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/4, Iter : 100/234,  Loss: 0.2676\n",
      "Epoch : 1/4, Iter : 200/234,  Loss: 0.2206\n",
      "Epoch : 2/4, Iter : 100/234,  Loss: 0.1538\n",
      "Epoch : 2/4, Iter : 200/234,  Loss: 0.1277\n",
      "Epoch : 3/4, Iter : 100/234,  Loss: 0.0998\n",
      "Epoch : 3/4, Iter : 200/234,  Loss: 0.1118\n",
      "Epoch : 4/4, Iter : 100/234,  Loss: 0.0388\n",
      "Epoch : 4/4, Iter : 200/234,  Loss: 0.0741\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN\n",
    "losses = [];\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data[0]);\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98       980\n",
      "          1       0.99      0.98      0.99      1135\n",
      "          2       0.98      0.97      0.98      1032\n",
      "          3       0.97      0.98      0.97      1010\n",
      "          4       0.98      0.98      0.98       982\n",
      "          5       0.98      0.97      0.97       892\n",
      "          6       0.99      0.97      0.98       958\n",
      "          7       0.96      0.97      0.97      1028\n",
      "          8       0.95      0.97      0.96       974\n",
      "          9       0.96      0.97      0.97      1009\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Test Set\n",
    "pred=[]\n",
    "true_label=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # convert tensors to numpy arrays\n",
    "        pred.append(predicted.numpy())\n",
    "        true_label.append(labels.numpy())\n",
    "        \n",
    "pred = np.concatenate(pred, axis=0 )\n",
    "true_label = np.concatenate(true_label, axis=0)\n",
    "\n",
    "print(classification_report(true_label, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
